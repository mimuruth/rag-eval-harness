{"id": "q-001", "question": "Why might an Azure OpenAI request return HTTP 429 errors?", "expected": "HTTP 429 errors commonly occur when token-per-minute or request-per-minute quotas are exceeded. Applications should implement retry with exponential backoff and consider reducing token usage.", "must_include": ["quota", "retry"], "must_not_include": ["increase temperature"], "retrieved": [{"doc_id": "ai-001", "title": "Azure OpenAI quota limits", "text": "Azure OpenAI enforces token-per-minute and request-per-minute quotas per model deployment. If a client exceeds these limits, the service may respond with HTTP 429 (Too Many Requests). Applications should implement retry with exponential backoff and consider reducing tokens or using a smaller model when appropriate.", "score": 0.3928205304084777}, {"doc_id": "sec-001", "title": "Key Vault secret access failures", "text": "Key Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.", "score": 0.04103597556484317}, {"doc_id": "ops-001", "title": "Observability for AI apps", "text": "Production AI applications should log prompt versions, request IDs, latency, token usage, and retrieval metadata. This enables debugging, cost monitoring, and regression analysis. Avoid logging sensitive content; redact or hash where appropriate.", "score": 0.03597170604026599}], "context": "[Doc 1] ai-001 — Azure OpenAI quota limits\nAzure OpenAI enforces token-per-minute and request-per-minute quotas per model deployment. If a client exceeds these limits, the service may respond with HTTP 429 (Too Many Requests). Applications should implement retry with exponential backoff and consider reducing tokens or using a smaller model when appropriate.\n\n[Doc 2] sec-001 — Key Vault secret access failures\nKey Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.\n\n[Doc 3] ops-001 — Observability for AI apps\nProduction AI applications should log prompt versions, request IDs, latency, token usage, and retrieval metadata. This enables debugging, cost monitoring, and regression analysis. Avoid logging sensitive content; redact or hash where appropriate.", "retrieval_latency_ms": 0.5, "answer": null, "llm_latency_ms": null, "model": null, "tokens": null}
{"id": "q-002", "question": "What are common causes of grounding failures in RAG systems?", "expected": "Grounding failures happen when the retrieved documents are irrelevant, incomplete, or poorly chunked. Improving chunking, filtering, and retrieval quality helps reduce hallucinations.", "must_include": ["retrieved", "documents"], "must_not_include": ["model bug"], "retrieved": [{"doc_id": "rag-001", "title": "RAG grounding failures", "text": "Retrieval-Augmented Generation (RAG) systems can hallucinate when retrieved documents are irrelevant, incomplete, or not provided clearly in the prompt. Improvements include better chunking, metadata filtering, hybrid search, and forcing the model to cite evidence from retrieved context.", "score": 0.3598526438245206}, {"doc_id": "sec-001", "title": "Key Vault secret access failures", "text": "Key Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.", "score": 0.03413215537615675}, {"doc_id": "agent-001", "title": "Tool calling reliability", "text": "Agents that call tools should validate inputs and outputs, enforce schemas, and implement timeouts and retries. Tool failures should be handled gracefully to avoid partial or misleading answers.", "score": 0.023653520619594078}], "context": "[Doc 1] rag-001 — RAG grounding failures\nRetrieval-Augmented Generation (RAG) systems can hallucinate when retrieved documents are irrelevant, incomplete, or not provided clearly in the prompt. Improvements include better chunking, metadata filtering, hybrid search, and forcing the model to cite evidence from retrieved context.\n\n[Doc 2] sec-001 — Key Vault secret access failures\nKey Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.\n\n[Doc 3] agent-001 — Tool calling reliability\nAgents that call tools should validate inputs and outputs, enforce schemas, and implement timeouts and retries. Tool failures should be handled gracefully to avoid partial or misleading answers.", "retrieval_latency_ms": 0.33, "answer": null, "llm_latency_ms": null, "model": null, "tokens": null}
{"id": "q-003", "question": "Why might Key Vault references fail in an Azure application?", "expected": "Key Vault references may fail if the managed identity lacks permission to read the secret or if network access is blocked due to Private Endpoint or DNS misconfiguration.", "must_include": ["managed identity", "permission"], "must_not_include": ["store secrets in code"], "retrieved": [{"doc_id": "sec-001", "title": "Key Vault secret access failures", "text": "Key Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.", "score": 0.4384573796380821}, {"doc_id": "id-001", "title": "Managed Identity access patterns", "text": "Managed identities must be granted the correct permissions to access downstream resources such as Key Vault, Storage, or Azure AI Search. Misconfigured RBAC or missing permissions can cause authentication failures even when the identity is enabled on the app.", "score": 0.16145130124733834}, {"doc_id": "ai-001", "title": "Azure OpenAI quota limits", "text": "Azure OpenAI enforces token-per-minute and request-per-minute quotas per model deployment. If a client exceeds these limits, the service may respond with HTTP 429 (Too Many Requests). Applications should implement retry with exponential backoff and consider reducing tokens or using a smaller model when appropriate.", "score": 0.06962147913964283}], "context": "[Doc 1] sec-001 — Key Vault secret access failures\nKey Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.\n\n[Doc 2] id-001 — Managed Identity access patterns\nManaged identities must be granted the correct permissions to access downstream resources such as Key Vault, Storage, or Azure AI Search. Misconfigured RBAC or missing permissions can cause authentication failures even when the identity is enabled on the app.\n\n[Doc 3] ai-001 — Azure OpenAI quota limits\nAzure OpenAI enforces token-per-minute and request-per-minute quotas per model deployment. If a client exceeds these limits, the service may respond with HTTP 429 (Too Many Requests). Applications should implement retry with exponential backoff and consider reducing tokens or using a smaller model when appropriate.", "retrieval_latency_ms": 0.32, "answer": null, "llm_latency_ms": null, "model": null, "tokens": null}
{"id": "q-004", "question": "What data should you capture for observability in an enterprise AI app?", "expected": "Capture prompt version, request ID, latency, token usage, and retrieval metadata. Avoid logging sensitive content and apply redaction where needed.", "must_include": ["latency", "token"], "must_not_include": ["log all secrets"], "retrieved": [{"doc_id": "ops-001", "title": "Observability for AI apps", "text": "Production AI applications should log prompt versions, request IDs, latency, token usage, and retrieval metadata. This enables debugging, cost monitoring, and regression analysis. Avoid logging sensitive content; redact or hash where appropriate.", "score": 0.212392052300939}, {"doc_id": "id-001", "title": "Managed Identity access patterns", "text": "Managed identities must be granted the correct permissions to access downstream resources such as Key Vault, Storage, or Azure AI Search. Misconfigured RBAC or missing permissions can cause authentication failures even when the identity is enabled on the app.", "score": 0.1252925032421126}, {"doc_id": "sec-001", "title": "Key Vault secret access failures", "text": "Key Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.", "score": 0.05174523449010762}], "context": "[Doc 1] ops-001 — Observability for AI apps\nProduction AI applications should log prompt versions, request IDs, latency, token usage, and retrieval metadata. This enables debugging, cost monitoring, and regression analysis. Avoid logging sensitive content; redact or hash where appropriate.\n\n[Doc 2] id-001 — Managed Identity access patterns\nManaged identities must be granted the correct permissions to access downstream resources such as Key Vault, Storage, or Azure AI Search. Misconfigured RBAC or missing permissions can cause authentication failures even when the identity is enabled on the app.\n\n[Doc 3] sec-001 — Key Vault secret access failures\nKey Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.", "retrieval_latency_ms": 0.31, "answer": null, "llm_latency_ms": null, "model": null, "tokens": null}
{"id": "q-005", "question": "How can you reduce LLM cost without breaking functionality?", "expected": "Reduce prompt size, summarize context, cache repeated responses, and consider routing simpler tasks to smaller models. Track token usage to validate savings.", "must_include": ["reduce", "cache"], "must_not_include": ["ignore tokens"], "retrieved": [{"doc_id": "ai-002", "title": "Prompt size and token cost", "text": "The total cost and latency of LLM calls are influenced by prompt and response token counts. Reducing prompt size, summarizing context, and caching repeated responses can lower cost. Streaming responses can improve perceived latency for end users.", "score": 0.21897353243603618}, {"doc_id": "rag-002", "title": "Chunking strategy basics", "text": "Chunking splits source documents into smaller passages for retrieval. Too-small chunks can lose context; too-large chunks can reduce retrieval precision. Use overlap and include metadata such as source, section, and timestamps to improve relevance and traceability.", "score": 0.08280894615656793}, {"doc_id": "eval-001", "title": "Why evaluation is required", "text": "LLM outputs can change due to prompt edits, model version changes, or retrieval differences. A repeatable evaluation harness with fixed test sets and metrics helps detect regressions before deployment and provides evidence of improvements.", "score": 0.06532836892401578}], "context": "[Doc 1] ai-002 — Prompt size and token cost\nThe total cost and latency of LLM calls are influenced by prompt and response token counts. Reducing prompt size, summarizing context, and caching repeated responses can lower cost. Streaming responses can improve perceived latency for end users.\n\n[Doc 2] rag-002 — Chunking strategy basics\nChunking splits source documents into smaller passages for retrieval. Too-small chunks can lose context; too-large chunks can reduce retrieval precision. Use overlap and include metadata such as source, section, and timestamps to improve relevance and traceability.\n\n[Doc 3] eval-001 — Why evaluation is required\nLLM outputs can change due to prompt edits, model version changes, or retrieval differences. A repeatable evaluation harness with fixed test sets and metrics helps detect regressions before deployment and provides evidence of improvements.", "retrieval_latency_ms": 0.29, "answer": null, "llm_latency_ms": null, "model": null, "tokens": null}
{"id": "q-006", "question": "Why do Private Endpoints often cause DNS-related connectivity issues?", "expected": "Private Endpoints require correct private DNS zone configuration so service hostnames resolve to private IPs. Missing zone links or incorrect DNS forwarding commonly causes name resolution failures.", "must_include": ["DNS", "private"], "must_not_include": ["disable private endpoint"], "retrieved": [{"doc_id": "net-001", "title": "Private Endpoint DNS resolution", "text": "When Private Endpoints are enabled, clients must resolve service FQDNs to private IP addresses. Missing private DNS zone links or incorrect DNS forwarding can cause name resolution failures. Verify DNS resolution from the client environment and ensure the correct private DNS zones are linked to the VNet.", "score": 0.5057174170002153}, {"doc_id": "id-001", "title": "Managed Identity access patterns", "text": "Managed identities must be granted the correct permissions to access downstream resources such as Key Vault, Storage, or Azure AI Search. Misconfigured RBAC or missing permissions can cause authentication failures even when the identity is enabled on the app.", "score": 0.046463406985303345}, {"doc_id": "sec-001", "title": "Key Vault secret access failures", "text": "Key Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.", "score": 0.03837835189576961}], "context": "[Doc 1] net-001 — Private Endpoint DNS resolution\nWhen Private Endpoints are enabled, clients must resolve service FQDNs to private IP addresses. Missing private DNS zone links or incorrect DNS forwarding can cause name resolution failures. Verify DNS resolution from the client environment and ensure the correct private DNS zones are linked to the VNet.\n\n[Doc 2] id-001 — Managed Identity access patterns\nManaged identities must be granted the correct permissions to access downstream resources such as Key Vault, Storage, or Azure AI Search. Misconfigured RBAC or missing permissions can cause authentication failures even when the identity is enabled on the app.\n\n[Doc 3] sec-001 — Key Vault secret access failures\nKey Vault access can fail if the managed identity lacks secret permissions or if network rules block access (e.g., Private Endpoint misconfiguration). If an app uses Key Vault references, failures may appear as missing configuration values or runtime initialization errors.", "retrieval_latency_ms": 0.28, "answer": null, "llm_latency_ms": null, "model": null, "tokens": null}
{"id": "q-007", "question": "What makes tool calling in agents reliable in production?", "expected": "Reliable tool calling requires schema validation, timeouts, retries, and clear error handling so tool failures do not produce misleading outputs.", "must_include": ["schema", "timeouts"], "must_not_include": ["always trust tool output"], "retrieved": [{"doc_id": "agent-001", "title": "Tool calling reliability", "text": "Agents that call tools should validate inputs and outputs, enforce schemas, and implement timeouts and retries. Tool failures should be handled gracefully to avoid partial or misleading answers.", "score": 0.3470189956420506}, {"doc_id": "ops-001", "title": "Observability for AI apps", "text": "Production AI applications should log prompt versions, request IDs, latency, token usage, and retrieval metadata. This enables debugging, cost monitoring, and regression analysis. Avoid logging sensitive content; redact or hash where appropriate.", "score": 0.06074160180599231}, {"doc_id": "eval-001", "title": "Why evaluation is required", "text": "LLM outputs can change due to prompt edits, model version changes, or retrieval differences. A repeatable evaluation harness with fixed test sets and metrics helps detect regressions before deployment and provides evidence of improvements.", "score": 0.0}], "context": "[Doc 1] agent-001 — Tool calling reliability\nAgents that call tools should validate inputs and outputs, enforce schemas, and implement timeouts and retries. Tool failures should be handled gracefully to avoid partial or misleading answers.\n\n[Doc 2] ops-001 — Observability for AI apps\nProduction AI applications should log prompt versions, request IDs, latency, token usage, and retrieval metadata. This enables debugging, cost monitoring, and regression analysis. Avoid logging sensitive content; redact or hash where appropriate.\n\n[Doc 3] eval-001 — Why evaluation is required\nLLM outputs can change due to prompt edits, model version changes, or retrieval differences. A repeatable evaluation harness with fixed test sets and metrics helps detect regressions before deployment and provides evidence of improvements.", "retrieval_latency_ms": 0.27, "answer": null, "llm_latency_ms": null, "model": null, "tokens": null}
{"id": "q-008", "question": "Why do LLM outputs change even if you did not change your code?", "expected": "Outputs can change due to model updates, prompt edits, retrieval differences, or configuration changes like temperature. A fixed evaluation set helps detect regressions.", "must_include": ["evaluation", "regressions"], "must_not_include": ["LLMs are deterministic"], "retrieved": [{"doc_id": "eval-001", "title": "Why evaluation is required", "text": "LLM outputs can change due to prompt edits, model version changes, or retrieval differences. A repeatable evaluation harness with fixed test sets and metrics helps detect regressions before deployment and provides evidence of improvements.", "score": 0.28211025824472835}, {"doc_id": "agent-001", "title": "Tool calling reliability", "text": "Agents that call tools should validate inputs and outputs, enforce schemas, and implement timeouts and retries. Tool failures should be handled gracefully to avoid partial or misleading answers.", "score": 0.041101534798157806}, {"doc_id": "ai-002", "title": "Prompt size and token cost", "text": "The total cost and latency of LLM calls are influenced by prompt and response token counts. Reducing prompt size, summarizing context, and caching repeated responses can lower cost. Streaming responses can improve perceived latency for end users.", "score": 0.03137308604545003}], "context": "[Doc 1] eval-001 — Why evaluation is required\nLLM outputs can change due to prompt edits, model version changes, or retrieval differences. A repeatable evaluation harness with fixed test sets and metrics helps detect regressions before deployment and provides evidence of improvements.\n\n[Doc 2] agent-001 — Tool calling reliability\nAgents that call tools should validate inputs and outputs, enforce schemas, and implement timeouts and retries. Tool failures should be handled gracefully to avoid partial or misleading answers.\n\n[Doc 3] ai-002 — Prompt size and token cost\nThe total cost and latency of LLM calls are influenced by prompt and response token counts. Reducing prompt size, summarizing context, and caching repeated responses can lower cost. Streaming responses can improve perceived latency for end users.", "retrieval_latency_ms": 0.28, "answer": null, "llm_latency_ms": null, "model": null, "tokens": null}
